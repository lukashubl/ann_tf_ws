\chapter{Verwenden des gelernten Models: Realtime Klassifizierer}
Das Modell, welches gerade angelernt wurde, wollen wir natürlich jetzt auch in einer wirklichen Anwendung verwenden. Dazu werden wir einen Realtime Klassifizierer programmieren, welcher ausgehend von der Webcam eines Notebooks oder PCs Ziffern einlesen und erkennen soll.
\section{Implementation}
Zuerst müssen wieder alle Abhängigkeiten importiert werden:
\lstset{language=Python}
\definecolor{listinggray}{gray}{0.95} 
\definecolor{keyword}{rgb}{0.4, 0, 0.1} 
\definecolor{comment}{rgb}{0, 0.4, 0}
% Zuweisen der Farben zu den entsprechenden Elementen ... 
\lstset{keywordstyle=\color{keyword}\bfseries} 
\lstset{commentstyle=\color{comment}} 
\lstset{backgroundcolor=\color{listinggray}}
\begin{lstlisting}
import tensorflow as tf
import cv2
import numpy as np
import matplotlib as matplotlib
import matplotlib.pyplot as plt
from PIL import Image
from resizeimage import resizeimage
import time
\end{lstlisting}
Dann muss wieder eine Sessionobjekt erzeugt werden.
\begin{lstlisting}
sess=tf.Session()
\end{lstlisting}
Dann starten wir die Aufnahme via Webcam, wodurch sich dann das Webcamlämpchen einschalten wird.
\begin{lstlisting}
cap = cv2.VideoCapture(0)
\end{lstlisting}
Wie vorher müssen auch wieder die MNIST Daten geladen werden. Dies wird getan, damit man die Labels extrahieren kann.
\begin{lstlisting}
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
\end{lstlisting}
Dann muss das Model wiederhergestellt werden. Dazu wird das Model von vorher geladen, also \emph{mnist\char`_workshop\char`_model-1.meta}. Daraus kann dann das ganze Model wiederhergestellt werden.
\begin{lstlisting}
saver = tf.train.import_meta_graph('mnist_workshop_model-1.meta')
saver.restore(sess,tf.train.latest_checkpoint('./'))
\end{lstlisting}
Als nächstes müssen die Tensoren vom wiederhergestellten Graphen extrahiert werden, also die Placeholder und die Prediction um wieder auf das Modell zugreifen zu können.
\begin{lstlisting}
graph = tf.get_default_graph()
y = graph.get_tensor_by_name("model:0")
x = graph.get_tensor_by_name("InputData:0")
y_ = graph.get_tensor_by_name("LabelData:0")
pred = tf.argmax(y,1)
\end{lstlisting}
Der nächste Schritt ist das Aufnehmen eines Bildes mit der Webcam. Da dies immer wieder geschieht, machen wir das in einer Endlosschleife. Dies bedeutet aber auch, dass das Skript nur mit \emph{STRG+C} oder einer Abbruchbedingung beendet werden kann.
\begin{lstlisting}
while TRUE:
    time.sleep(0)
\end{lstlisting}
Mit den folgenden Befehlen wird ein Bild aufgenommen, ein Bereich des Bildes ausgewählt, dieser Bereich transformiert auf eine 28x28 Matrix und von RGB in Graustufen umgewandelt.
\begin{lstlisting}
    ret, image_np = cap.read()
    image_np = image_np[100:660, 100:660]
    image_np = cv2.resize(image_np, (28, 28))
    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
\end{lstlisting}
Als nächstes werden um das Bild zu vereinfachen, alle Pixel mit einem Wert über einem gewissen Threshold (in unserem Fall 50) auf den Maximalwert(255) gesetzt.
\begin{lstlisting}
    for i in range(0,28):
        for a in range(0,28):
            if image_np[i,a] > 50:
                image_np[i,a] = 255
\end{lstlisting}
Nun wandeln wir der Einfachheit halber das Array in ein numpy Array um. Numpy ist ein Python package welches sich auf mathematische Operationen spezialisiert hat und dies deshalb sehr effizient realisiert.
Da die MNIST Daten mit welchem das Model gelernt wurden nur einen Scope von 0 bis 1 und nicht 0 bis 255 hat, muss dieser Wert mit 255 dividiert werden. Da 255 weiß ist aber bei den MNIST Daten 0 weiß ist, wird vom Quotienten noch 1 abgezogen und der Absolutwert genommen. So kommen wir auf den selben Scope wie die MNIST Daten also 0(weiß) und 1(schwarz).
\begin{lstlisting}
    newarr = np.array(image_np)
    newarr = abs((newarr / 255) - 1)
    newshape = newarr.shape
\end{lstlisting}
Dieses Array muss dann noch in eine eindimensoinale Matrix umgewandlet werden um dem Scope des Eingangs des Modells gerecht zu werden. Dazu wird dass Array zuerst in ein eindimensionales Array umgewandlet und dann in vom eindimensionalen Array in eine eindimensionale Matrix.
\begin{lstlisting}
    new_flat_arr = newarr.ravel()
    newvector = np.matrix(new_flat_arr)
\end{lstlisting}
Diese eindimensionale Matrix muss jetzt nur noch durch den Predictor geschickt werden und man erhält ein Ergebniss. Der Predictor benötigt als Y-Value noch die Testlabels welche wir ganz am Anfang ausgelesen haben.
\begin{lstlisting}
    erg = sess.run(pred, feed_dict={x: newvector, y_: mnist.test.labels})
    print(erg)
\end{lstlisting}
Um das Bild un das Ergebniss in Realtime anzeigen zu können müssen wir noch folgenden Code einfügen. Der Code beinhaltet die Positionierung des Ergebnisses auf dem Plot, das Anzeigen des Bildes und das Anzeigen des Ergebnisses. Genauer wird auf den Code nicht eingegangen, da er relativ selbstverständlich ist.
\begin{lstlisting}
    #ergebnisse zeigen im realtime window
    font = cv2.FONT_HERSHEY_SIMPLEX
    pts = np.array([[120,100],[420,100],[420,420],[120,420]], np.int32)
    pts = pts.reshape((-1,1,2))
    cross = np.array([[300,0],[300,560],[0,560],[0,280],[560,280],[560,0]], np.int32)

    image_np = cv2.resize(image_np, (560,560))

    font = cv2.FONT_HERSHEY_SIMPLEX
    bottomLeftCornerOfText = (10,500)
    fontScale = 1
    fontColor = (0,0,0)
    lineType = 2

    cv2.putText(image_np, str(erg[0]),
        bottomLeftCornerOfText,
        font,
        fontScale,
        fontColor,
        lineType)
    cv2.polylines(image_np,[cross],True,(0,0,0))
\end{lstlisting}
Um das Programm jederzeit abbrechen zu können fehlt jetzt noch einen Abbruchbedingung
\begin{lstlisting}
    cv2.imshow('object detection', image_np)
    if cv2.waitKey(25) & 0xFF == ord('q'):
        cv2.destroyAllWindows()
        break
\end{lstlisting}
Und schon funktioniert unser selbst programmierter Realtime Klassifizierer.

\label{cha:Usage}